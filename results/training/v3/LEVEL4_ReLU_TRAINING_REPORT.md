# V3 Level 4 ReLU 훈련 보고서

**훈련 완료일**: 2025-10-01
**훈련 시간**: 4148.75초 (약 69분)
**모델 아키텍처**: NPU Level 4 최적화 + ReLU 활성화
**에포크 수**: 100
**배치 크기**: 16

---

## 📊 **최종 성능 지표**

### **최종 에포크 (100) 결과**
| 지표 | 값 | 설명 |
|------|-----|------|
| **mAP50** | **0.878** | 87.8% AP (IoU=0.5) |
| **mAP50-95** | **0.746** | 74.6% AP (IoU=0.5:0.95) |
| **Precision** | **0.854** | 85.4% 정밀도 |
| **Recall** | **0.808** | 80.8% 재현율 |
| **Box Loss** | 0.536 | 바운딩박스 손실 |
| **Class Loss** | 0.521 | 분류 손실 |
| **DFL Loss** | 0.992 | Distribution Focal Loss |

---

## 🎯 **훈련 설정**

### **모델 구성**
- **베이스 모델**: YOLOv11n
- **최적화 레벨**: Level 4 (완전 최적화)
- **활성화 함수**: ReLU (NPU 호환성 우선)
- **입력 크기**: 640×640
- **클래스 수**: 교통표지판 Detection

### **하이퍼파라미터**
| 파라미터 | 값 | 설명 |
|----------|-----|------|
| **학습률 (초기)** | 0.003 | 초기 학습률 |
| **학습률 (최종)** | 0.0001 | 최종 학습률 (10% 감소) |
| **모멘텀** | 0.9 | SGD 모멘텀 |
| **가중치 감쇠** | 0.001 | 정규화 |
| **Warmup 에포크** | 5 | 학습률 워밍업 |
| **Box Loss 가중치** | 7.5 | 바운딩박스 손실 가중치 |
| **Class Loss 가중치** | 0.5 | 분류 손실 가중치 |

---

## 📈 **훈련 진행 분석**

### **성능 향상 추이**
- **초기 성능** (1 에포크): mAP50 0.002 → **최종**: 0.878 (**439배 향상**)
- **중간 체크포인트** (50 에포크): mAP50 약 0.7-0.8
- **수렴 시점**: 에포크 80-90 구간에서 안정화

### **손실 함수 변화**
- **Box Loss**: 2.56 → 0.536 (79% 감소)
- **Class Loss**: 6.06 → 0.521 (91% 감소)
- **DFL Loss**: 4.36 → 0.992 (77% 감소)

---

## 🔍 **Level 4 최적화 특징**

### **아키텍처 변경사항**
1. **Backbone 최적화**:
   - C3k2 → C2f 변환 (완전 적용)
   - Efficient attention 제거

2. **Neck 최적화**:
   - FPN/PAN 구조 단순화
   - 연산 복잡도 최소화

3. **Head 최적화**:
   - Detection head 경량화
   - NPU 친화적 연산으로 변경

### **NPU 호환성**
- **ReLU 활성화**: NPU 최적화 우선
- **양자화 준비**: INT8 변환 호환성
- **메모리 효율성**: 엣지 디바이스 배포 최적화

---

## ⚡ **성능 비교**

### **V3 시리즈 내 비교** (예상)
| 모델 | mAP50 | NPU 호환성 | 특징 |
|------|-------|------------|------|
| Level 2 ReLU | ~0.807 | 99.0% | 기본 최적화 |
| Level 3 ReLU | ~0.850 | 96.2% | 중급 최적화 |
| **Level 4 ReLU** | **0.878** | **96.2%** | **완전 최적화** |

### **활성화 함수 비교** (동일 레벨)
- **Level 4 ReLU**: 87.8% mAP50 (현재 모델)
- **Level 4 LeakyReLU**: 90.1% mAP50 (정확도 우수)
- **NPU 호환성**: ReLU > LeakyReLU

---

## 💡 **핵심 성과**

### **훈련 성공 요인**
1. **안정적 수렴**: 100 에포크 완주
2. **높은 정확도**: 87.8% mAP50 달성
3. **균형잡힌 성능**: Precision/Recall 균형
4. **NPU 최적화**: ReLU 활성화로 NPU 호환성 확보

### **특장점**
- **교통표지판 Detection 특화**: 실용적 성능
- **엣지 배포 준비**: NPU 호환성 우선
- **메모리 효율성**: Level 4 최적화 적용

---

## 🚀 **배포 권장사항**

### **최적 사용 시나리오**
1. **자율주행 시스템**: 높은 정확도 + NPU 가속
2. **교통 모니터링**: 실시간 표지판 인식
3. **임베디드 시스템**: 메모리 제약 환경

### **NPU 배포 전략**
- **양자화**: INT8 Full Integer 권장
- **메모리**: 3-4MB 예상 크기
- **추론 속도**: NPU 가속으로 20-30ms 예상

---

## 📋 **훈련 메타데이터**

```yaml
모델명: level4-relu_20251001_122011
데이터셋: /lambda/nfs/yolo/data/dataset/data.yaml
프리트레인: yolov11n.pt
옵티마이저: SGD
시드: 0 (재현성 보장)
GPU: CUDA Device 0
워커: 8개 프로세스
```

---

## 🎯 **결론**

V3 Level 4 ReLU 모델은 **87.8% mAP50**을 달성하여 높은 정확도와 NPU 호환성을 모두 확보했습니다. Level 4 최적화를 통해 교통표지판 detection에 특화된 실용적 성능을 보여주며, **엣지 디바이스 배포에 최적화**된 모델입니다.

**추천**: 실시간 추론과 NPU 가속이 필요한 프로덕션 환경에 적합한 모델입니다.

---

**보고서 생성일**: 2025-10-02
**훈련 로그 위치**: `results/training/v3/level4_relu/`