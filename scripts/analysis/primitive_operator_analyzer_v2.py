#!/usr/bin/env python3
"""
YOLOv11 Primitive Operator Analyzer v2
ë³µí•© ëª¨ë“ˆ(C2PSA, C2f ë“±)ì„ primitive operatorë¡œ ë¶„í•´í•˜ì—¬ ë¶„ì„í•˜ê³  Markdown ë¦¬í¬íŠ¸ ìƒì„±
"""

import torch
import torch.nn as nn
import argparse
from collections import Counter, defaultdict
from ultralytics import YOLO
import sys
import json
from pathlib import Path
from datetime import datetime

class EthosNCompatibilityChecker:
    """Ethos-N NPU í˜¸í™˜ì„± ì²´í¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.ethos_n_data = self._load_ethos_n_specs()

    def _load_ethos_n_specs(self):
        """Ethos-N ì§€ì› operator ì •ë³´ ë¡œë“œ"""
        try:
            script_dir = Path(__file__).parent.parent.parent
            json_path = script_dir / "docs" / "ethos-n" / "ethos_n_supported_ops.json"

            with open(json_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸ Ethos-N ìŠ¤í™ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def is_supported(self, operator_name):
        """Operatorê°€ Ethos-Nì—ì„œ ì§€ì›ë˜ëŠ”ì§€ í™•ì¸"""
        if not self.ethos_n_data:
            return "â“ í™•ì¸ ë¶ˆê°€"

        supported_ops = self.ethos_n_data.get("supported_operators", [])

        # PyTorch operatorë¥¼ Ethos-N operatorë¡œ ë§¤í•‘
        pytorch_to_ethos_mapping = {
            'Conv2d': 'Conv2d',
            'Linear': 'Linear',
            'ReLU': 'ReLU',
            'LeakyReLU': 'LeakyReLU',
            'MaxPool2d': 'MaxPool2d',
            'AvgPool2d': 'AvgPool2d',
            'Add': 'Add',
            'Multiply': 'Mul',
            'Concatenate': 'Concat',
            'Split': 'Split',
            'Sigmoid': 'Sigmoid',
            'Tanh': 'Tanh',
            'Reshape': 'Reshape',
            'Flatten': 'Reshape',
            'Upsample': 'Resize',
            'Interpolate': 'Resize',
            'ConvTranspose2d': 'ConvTranspose2d',
            'Transpose': 'Transpose',
            # Functional ë²„ì „ë“¤
            'ReLU_F': 'ReLU',
            'LeakyReLU_F': 'LeakyReLU',
            'Conv2d_F': 'Conv2d',
            'MaxPool2d_F': 'MaxPool2d',
            'AvgPool2d_F': 'AvgPool2d'
        }

        ethos_op = pytorch_to_ethos_mapping.get(operator_name)

        if ethos_op in supported_ops:
            return "âœ… ì™„ì „ ì§€ì›"
        elif operator_name == 'BatchNorm2d':
            return "ğŸ”„ Conv ìœµí•©ë¨"
        elif operator_name in ['SiLU', 'GELU', 'Mish', 'Softmax', 'LayerNorm', 'GroupNorm', 'MatMul', 'SiLU_F', 'GELU_F', 'Softmax_F']:
            return "âŒ ë¯¸ì§€ì›"
        else:
            return "â“ í™•ì¸ í•„ìš”"

    def get_operator_constraints(self, operator_name):
        """Operatorì˜ ì œì•½ ì¡°ê±´ ë°˜í™˜"""
        if not self.ethos_n_data:
            return None

        constraints = self.ethos_n_data.get("operator_constraints", {})
        pytorch_to_ethos_mapping = {
            'Conv2d': 'Conv2d',
            'MaxPool2d': 'MaxPool2d',
            'AvgPool2d': 'AvgPool2d'
        }

        ethos_op = pytorch_to_ethos_mapping.get(operator_name)
        return constraints.get(ethos_op)

class PrimitiveOperatorExtractor:
    """ëª¨ë“ˆì„ primitive operatorë¡œ ë¶„í•´í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        self.primitive_ops = Counter()
        self.module_breakdown = defaultdict(list)
        self.traced_ops = []
        self.compatibility_checker = EthosNCompatibilityChecker()

    def extract_primitives(self, module, prefix=""):
        """ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“ˆì„ primitive operatorë¡œ ë¶„í•´"""

        # Primitive operators (ë” ì´ìƒ ë¶„í•´ë˜ì§€ ì•ŠëŠ” ì—°ì‚°ìë“¤)
        primitive_types = {
            nn.Conv2d, nn.Linear, nn.BatchNorm2d, nn.LayerNorm, nn.GroupNorm,
            nn.ReLU, nn.LeakyReLU, nn.SiLU, nn.GELU, nn.Mish,
            nn.MaxPool2d, nn.AvgPool2d, nn.AdaptiveAvgPool2d, nn.AdaptiveMaxPool2d,
            nn.Dropout, nn.Dropout2d, nn.Upsample, nn.Sigmoid, nn.Tanh,
            nn.Softmax, nn.LogSoftmax, nn.Flatten, nn.Identity, nn.ConvTranspose2d
        }

        # Swish í™œì„±í™” í•¨ìˆ˜ í™•ì¸ (PyTorch ë²„ì „ì— ë”°ë¼ ë‹¤ë¦„)
        try:
            primitive_types.add(nn.Swish)
        except AttributeError:
            pass  # Swishê°€ ì—†ëŠ” PyTorch ë²„ì „

        module_type = type(module).__name__

        # í˜„ì¬ ëª¨ë“ˆì´ primitiveì¸ì§€ í™•ì¸
        if type(module) in primitive_types:
            self.primitive_ops[module_type] += 1
            self.module_breakdown[prefix].append(module_type)
            return

        # íŠ¹ë³„í•œ ê²½ìš°: Functional operations
        if hasattr(module, 'forward'):
            # ëª¨ë“ˆì˜ forward ë©”ì„œë“œë¥¼ ë¶„ì„í•˜ì—¬ functional ops ì°¾ê¸°
            self._analyze_forward_functional(module, prefix)

        # í•˜ìœ„ ëª¨ë“ˆ ì¬ê·€ ë¶„ì„
        children = list(module.named_children())
        if children:
            for name, child in children:
                child_prefix = f"{prefix}.{name}" if prefix else name
                self.extract_primitives(child, child_prefix)
        else:
            # Leaf moduleì´ì§€ë§Œ primitiveê°€ ì•„ë‹Œ ê²½ìš°
            if module_type not in ['Sequential', 'ModuleList', 'ModuleDict']:
                self.primitive_ops[f"Unknown_{module_type}"] += 1
                self.module_breakdown[prefix].append(f"Unknown_{module_type}")

    def _analyze_forward_functional(self, module, prefix):
        """Forward ë©”ì„œë“œì—ì„œ functional operations ë¶„ì„"""
        import inspect

        try:
            source = inspect.getsource(module.forward)

            # ì¼ë°˜ì ì¸ functional operations íŒ¨í„´ ë§¤ì¹­
            functional_patterns = {
                'torch.cat': 'Concatenate',
                'torch.split': 'Split',
                'torch.chunk': 'Chunk',
                'torch.add': 'Add',
                'torch.mul': 'Multiply',
                'torch.matmul': 'MatMul',
                'F.relu': 'ReLU_F',
                'F.leaky_relu': 'LeakyReLU_F',
                'F.silu': 'SiLU_F',
                'F.gelu': 'GELU_F',
                'F.softmax': 'Softmax_F',
                'F.interpolate': 'Interpolate',
                'F.max_pool2d': 'MaxPool2d_F',
                'F.avg_pool2d': 'AvgPool2d_F',
                'F.conv2d': 'Conv2d_F',
                'F.linear': 'Linear_F'
            }

            for pattern, op_name in functional_patterns.items():
                if pattern in source:
                    self.primitive_ops[op_name] += source.count(pattern)
                    self.module_breakdown[prefix].append(op_name)

        except (OSError, TypeError):
            # Source codeë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ëŠ” ê²½ìš°
            pass

def analyze_primitive_operators(model_path, trace_forward=False, save_report=True):
    """ëª¨ë¸ì˜ primitive operator êµ¬ì„±ì„ ë¶„ì„í•˜ê³  Markdown ë¦¬í¬íŠ¸ ìƒì„±"""

    print(f"ğŸ”¬ Primitive Operator ë¶„ì„ ì‹œì‘: {model_path}")
    print("=" * 70)

    # ë¦¬í¬íŠ¸ ë‚´ìš©ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    report_lines = []

    # í—¤ë” ì •ë³´
    model_name = Path(model_path).name
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    report_lines.extend([
        f"# Primitive Operator Analysis Report",
        f"",
        f"**Model**: `{model_name}`",
        f"**Analysis Date**: {timestamp}",
        f"**Tool**: YOLOv11 Primitive Operator Analyzer v2",
        f"",
        f"---",
        f""
    ])

    try:
        # ëª¨ë¸ ë¡œë“œ
        model = YOLO(model_path)
        pytorch_model = model.model

        # Primitive operator ì¶”ì¶œê¸°
        extractor = PrimitiveOperatorExtractor()

        # Ethos-N í˜¸í™˜ì„± ì •ë³´ ì¶œë ¥
        if extractor.compatibility_checker.ethos_n_data:
            print(f"âœ… Ethos-N ìŠ¤í™ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
            supported_ops = extractor.compatibility_checker.ethos_n_data.get("supported_operators", [])
            print(f"ğŸ“‹ ì§€ì›ë˜ëŠ” operator: {len(supported_ops)}ê°œ")
        else:
            print(f"âš ï¸ Ethos-N ìŠ¤í™ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ - ê¸°ë³¸ í˜¸í™˜ì„± ì •ë³´ ì‚¬ìš©")

        print("ğŸ“‹ ëª¨ë“ˆë³„ Primitive Operator ë¶„í•´:")
        print("-" * 70)

        # ëª¨ë“ˆ ë¶„ì„ ì„¹ì…˜ ì‹œì‘
        report_lines.extend([
            f"## ğŸ” Module-Level Primitive Operator Breakdown",
            f"",
            f"| Module | Type | Conv2d | BatchNorm | Activations | Other Ops | Parameters |",
            f"|--------|------|--------|-----------|-------------|-----------|------------|"
        ])

        composite_modules_info = []

        # ëª¨ë“  ëª¨ë“ˆì„ primitive operatorë¡œ ë¶„í•´
        for name, module in pytorch_model.named_modules():
            if name:  # ë£¨íŠ¸ ëª¨ë“ˆ ì œì™¸
                module_type = type(module).__name__

                # í•´ë‹¹ ëª¨ë“ˆë§Œ ë¶„ì„
                module_extractor = PrimitiveOperatorExtractor()
                module_extractor.extract_primitives(module, name)

                # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
                total_params = sum(p.numel() for p in module.parameters())

                if module_extractor.primitive_ops:
                    conv_count = module_extractor.primitive_ops.get('Conv2d', 0)
                    bn_count = module_extractor.primitive_ops.get('BatchNorm2d', 0)
                    activation_count = sum(module_extractor.primitive_ops.get(act, 0)
                                         for act in ['SiLU', 'ReLU', 'LeakyReLU', 'GELU'])
                    other_count = sum(v for k, v in module_extractor.primitive_ops.items()
                                    if k not in ['Conv2d', 'BatchNorm2d', 'SiLU', 'ReLU', 'LeakyReLU', 'GELU'])

                    # ë³µí•© ëª¨ë“ˆë§Œ ìƒì„¸ ì •ë³´ ì €ì¥
                    if module_type in ['C2f', 'C3k2', 'C2PSA', 'SPPF', 'Detect']:
                        composite_modules_info.append({
                            'name': name,
                            'type': module_type,
                            'ops': dict(module_extractor.primitive_ops),
                            'params': total_params
                        })

                    # ì½˜ì†” ì¶œë ¥
                    print(f"\nğŸ” ë¶„ì„ ì¤‘: {name} ({module_type})")
                    for op_type, count in module_extractor.primitive_ops.items():
                        print(f"  â””â”€ {op_type}: {count}ê°œ")
                        extractor.primitive_ops[op_type] += count

                    # Markdown í…Œì´ë¸”ì— ì¶”ê°€ (ë³µí•© ëª¨ë“ˆë§Œ)
                    if module_type in ['C2f', 'C3k2', 'C2PSA', 'SPPF', 'Detect']:
                        report_lines.append(
                            f"| `{name}` | {module_type} | {conv_count} | {bn_count} | {activation_count} | {other_count} | {total_params:,} |"
                        )

        # Forward pass tracing (ì„ íƒì )
        if trace_forward:
            print(f"\nğŸ”¬ Forward Pass Tracing:")
            print("-" * 70)
            traced_ops = trace_forward_pass(pytorch_model)
            for op in traced_ops:
                print(f"  â””â”€ {op}")
                extractor.primitive_ops[f"Traced_{op}"] += 1

        # ì „ì²´ í†µê³„
        print(f"\nğŸ“Š Primitive Operator í†µê³„:")
        print("-" * 70)

        total_primitives = sum(extractor.primitive_ops.values())

        # í†µê³„ í…Œì´ë¸” ìƒì„±
        report_lines.extend([
            f"",
            f"## ğŸ“Š Overall Primitive Operator Statistics",
            f"",
            f"**Total Primitive Operators**: {total_primitives:,}",
            f"",
            f"| Operator Type | Count | Percentage | NPU Support |",
            f"|---------------|-------|------------|-------------|"
        ])

        for op_type, count in extractor.primitive_ops.most_common():
            percentage = (count / total_primitives) * 100
            status = extractor.compatibility_checker.is_supported(op_type)
            print(f"{op_type:25} | {count:>4}ê°œ | {percentage:>6.2f}% | {status}")

            # Markdown í…Œì´ë¸”ì— ì¶”ê°€
            report_lines.append(f"| {op_type} | {count} | {percentage:.1f}% | {status} |")

        print(f"\nì´ Primitive Operator ìˆ˜: {total_primitives:,}ê°œ")

        # NPU í˜¸í™˜ì„± ë¶„ì„
        compatibility_info = analyze_primitive_npu_compatibility(extractor.primitive_ops, report_lines)

        # ë³µí•© ëª¨ë“ˆ ë¶„ì„
        analyze_composite_modules_md(composite_modules_info, report_lines)

        # ë¦¬í¬íŠ¸ ì €ì¥
        if save_report:
            save_analysis_report(model_path, report_lines, extractor.primitive_ops, compatibility_info)

        return True

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

def analyze_primitive_npu_compatibility(primitive_ops, report_lines):
    """Primitive operator ìˆ˜ì¤€ì—ì„œ NPU í˜¸í™˜ì„± ë¶„ì„ (Ethos-N JSON ê¸°ë°˜)"""

    print(f"\nğŸ¯ Primitive Operator NPU í˜¸í™˜ì„± (Ethos-N ê¸°ë°˜):")
    print("-" * 70)

    # Ethos-N í˜¸í™˜ì„± ì²´ì»¤ ìƒì„±
    compatibility_checker = EthosNCompatibilityChecker()

    # Ethos-N ìŠ¤í™ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if compatibility_checker.ethos_n_data:
        supported_ops = compatibility_checker.ethos_n_data.get("supported_operators", [])
        print(f"ğŸ“‹ Ethos-N ì§€ì› operator ëª©ë¡: {', '.join(supported_ops)}")
        print("-" * 70)

    compatible_count = 0
    conditional_count = 0
    incompatible_count = 0
    unknown_count = 0
    total_ops = sum(primitive_ops.values())

    # Markdownì— NPU í˜¸í™˜ì„± ì„¹ì…˜ ì¶”ê°€
    if compatibility_checker.ethos_n_data:
        device_info = compatibility_checker.ethos_n_data.get("npu_device", "Arm Ethos-N")
        tensor_reqs = compatibility_checker.ethos_n_data.get("tensor_requirements", {})

        report_lines.extend([
            f"",
            f"## ğŸ¯ NPU Compatibility Analysis",
            f"",
            f"**NPU Device**: {device_info}",
            f"**Analysis Based On**: {compatibility_checker.ethos_n_data.get('description', 'Ethos-N supported operators')}",
            f"",
            f"### Tensor Requirements",
            f"- **Supported Data Types**: {', '.join(tensor_reqs.get('datatypes', []))}",
            f"- **Max Dimensions**: {tensor_reqs.get('max_dimensions', 'N/A')}",
            f"- **Max Batch Size**: {tensor_reqs.get('max_batch_size', 'N/A')}",
            f"- **Tensor Format**: {tensor_reqs.get('tensor_format', 'N/A')}",
            f"- **Quantization**: {tensor_reqs.get('quantization', 'N/A')}",
            f"",
            f"| Operator Type | Count | Percentage | NPU Support Status | Constraints |",
            f"|---------------|-------|------------|-------------------|-------------|"
        ])
    else:
        report_lines.extend([
            f"",
            f"## ğŸ¯ NPU Compatibility Analysis",
            f"",
            f"âš ï¸ Ethos-N ìŠ¤í™ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            f"",
            f"| Operator Type | Count | Percentage | NPU Support Status |",
            f"|---------------|-------|------------|-------------------|"
        ])

    for op_type, count in primitive_ops.items():
        status = compatibility_checker.is_supported(op_type)
        percentage = (count / total_ops) * 100
        constraints = compatibility_checker.get_operator_constraints(op_type)

        print(f"{op_type:25} | {count:>4}ê°œ | {status}")

        # Markdownì— ì¶”ê°€ (ì œì•½ ì¡°ê±´ í¬í•¨)
        if constraints:
            constraints_str = f"Kernel: {constraints.get('kernel_sizes', 'N/A')}, Stride: {constraints.get('strides', 'N/A')}"
            report_lines.append(f"| {op_type} | {count} | {percentage:.1f}% | {status} | {constraints_str} |")
        else:
            if compatibility_checker.ethos_n_data:
                report_lines.append(f"| {op_type} | {count} | {percentage:.1f}% | {status} | - |")
            else:
                report_lines.append(f"| {op_type} | {count} | {percentage:.1f}% | {status} |")

        if status.startswith('âœ…'):
            compatible_count += count
        elif status.startswith('ğŸ”„'):
            conditional_count += count
        elif status.startswith('âŒ'):
            incompatible_count += count
        else:
            unknown_count += count

    # í˜¸í™˜ì„± ìš”ì•½
    compatibility_rate = compatible_count / total_ops * 100
    conditional_rate = conditional_count / total_ops * 100
    incompatible_rate = incompatible_count / total_ops * 100
    overall_compatibility = (compatible_count + conditional_count * 0.5) / total_ops * 100

    print(f"\nğŸ“Š Primitive Level NPU í˜¸í™˜ì„±:")
    print(f"âœ… ì™„ì „ ì§€ì›:     {compatible_count:>4}ê°œ ({compatibility_rate:>5.1f}%)")
    print(f"âš ï¸ ì¡°ê±´ë¶€ ì§€ì›:   {conditional_count:>4}ê°œ ({conditional_rate:>5.1f}%)")
    print(f"âŒ ë¯¸ì§€ì›:       {incompatible_count:>4}ê°œ ({incompatible_rate:>5.1f}%)")
    if unknown_count > 0:
        print(f"â“ í™•ì¸ í•„ìš”:     {unknown_count:>4}ê°œ ({(unknown_count/total_ops)*100:>5.1f}%)")
    print(f"\nğŸ¯ ì „ì²´ í˜¸í™˜ì„±: {overall_compatibility:.1f}%")

    # Markdownì— ìš”ì•½ ì¶”ê°€
    report_lines.extend([
        f"",
        f"### Compatibility Summary",
        f"",
        f"| Support Level | Count | Percentage |",
        f"|---------------|-------|------------|",
        f"| âœ… Fully Supported | {compatible_count} | {compatibility_rate:.1f}% |",
        f"| âš ï¸ Conditional Support | {conditional_count} | {conditional_rate:.1f}% |",
        f"| âŒ Not Supported | {incompatible_count} | {incompatible_rate:.1f}% |"
    ])

    if unknown_count > 0:
        report_lines.append(f"| â“ Unknown | {unknown_count} | {(unknown_count/total_ops)*100:.1f}% |")

    report_lines.extend([
        f"",
        f"**Overall NPU Compatibility Score**: {overall_compatibility:.1f}%",
        f""
    ])

    return {
        'compatible': compatible_count,
        'conditional': conditional_count,
        'incompatible': incompatible_count,
        'unknown': unknown_count,
        'overall_score': overall_compatibility
    }

def analyze_composite_modules_md(modules_info, report_lines):
    """ë³µí•© ëª¨ë“ˆ ë¶„ì„ì„ Markdownì— ì¶”ê°€"""

    report_lines.extend([
        f"## ğŸ—ï¸ Composite Module Analysis",
        f"",
        f"Detailed breakdown of complex modules:",
        f""
    ])

    for module_info in modules_info:
        name = module_info['name']
        module_type = module_info['type']
        ops = module_info['ops']
        params = module_info['params']
        memory_mb = params * 4 / (1024**2)  # 4 bytes per float32

        report_lines.extend([
            f"### {name} ({module_type})",
            f"",
            f"- **Parameters**: {params:,}",
            f"- **Memory Usage**: {memory_mb:.2f} MB",
            f"",
            f"**Primitive Operators**:",
            f""
        ])

        for op_type, count in ops.items():
            report_lines.append(f"- {op_type}: {count}")

        report_lines.append(f"")

def save_analysis_report(model_path, report_lines, primitive_ops, compatibility_info):
    """ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ Markdown íŒŒì¼ë¡œ ì €ì¥"""

    model_name = Path(model_path).stem
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # docs ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
    docs_dir = Path('docs/analysis')
    docs_dir.mkdir(parents=True, exist_ok=True)

    # íŒŒì¼ëª… ìƒì„±
    report_filename = f"primitive_operator_analysis_{model_name}_{timestamp}.md"
    report_path = docs_dir / report_filename

    # ì¶”ê°€ ìš”ì•½ ì •ë³´
    report_lines.extend([
        f"## ğŸ“ˆ Optimization Recommendations",
        f"",
        f"Based on the analysis, here are the key optimization recommendations:",
        f""
    ])

    # SiLU ìµœì í™” ê¶Œì¥ì‚¬í•­
    silu_count = primitive_ops.get('SiLU', 0)
    if silu_count > 0:
        total_ops = sum(primitive_ops.values())
        silu_percentage = (silu_count / total_ops) * 100
        report_lines.extend([
            f"### ğŸ”¥ Priority 1: Replace SiLU Activations",
            f"",
            f"- **Impact**: {silu_count} SiLU operators ({silu_percentage:.1f}% of total)",
            f"- **Solution**: Replace with `LeakyReLU(negative_slope=0.1)`",
            f"- **Expected Improvement**: +{silu_percentage:.1f}% NPU compatibility",
            f""
        ])

    # BatchNorm ìœµí•© ê¶Œì¥ì‚¬í•­
    bn_count = primitive_ops.get('BatchNorm2d', 0)
    conv_count = primitive_ops.get('Conv2d', 0)
    if bn_count > 0:
        report_lines.extend([
            f"### ğŸ”„ Priority 2: BatchNorm-Conv Fusion",
            f"",
            f"- **Impact**: {bn_count} BatchNorm2d operators can be fused with Conv2d",
            f"- **Solution**: Enable BatchNorm fusion during model optimization",
            f"- **Expected Improvement**: Reduced memory usage and faster inference",
            f""
        ])

    # ì „ì²´ ê²°ë¡ 
    report_lines.extend([
        f"## ğŸ¯ Conclusion",
        f"",
        f"- **Total Primitive Operators**: {sum(primitive_ops.values()):,}",
        f"- **NPU Compatibility Score**: {compatibility_info['overall_score']:.1f}%",
        f"- **Primary Optimization Target**: SiLU activation functions",
        f"- **Secondary Optimization**: BatchNorm-Conv fusion",
        f"",
        f"---",
        f"",
        f"*Analysis generated by YOLOv11 Primitive Operator Analyzer v2*"
    ])

    # íŒŒì¼ ì €ì¥
    try:
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))

        print(f"\nğŸ“„ ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_path}")
        return report_path

    except Exception as e:
        print(f"âŒ ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

def trace_forward_pass(model):
    """Forward passë¥¼ traceí•˜ì—¬ ì‹¤ì œ ì‹¤í–‰ë˜ëŠ” operations ì¶”ì """
    traced_ops = []

    # Hookì„ ì‚¬ìš©í•œ operation tracing
    def trace_hook(module, input, output):
        op_name = type(module).__name__
        if op_name not in ['Sequential', 'ModuleList']:
            traced_ops.append(op_name)

    # ëª¨ë“  ëª¨ë“ˆì— hook ë“±ë¡
    hooks = []
    for module in model.modules():
        hook = module.register_forward_hook(trace_hook)
        hooks.append(hook)

    try:
        # Dummy inputìœ¼ë¡œ forward pass ì‹¤í–‰
        dummy_input = torch.randn(1, 3, 640, 640)
        with torch.no_grad():
            _ = model(dummy_input)
    except Exception as e:
        print(f"âš ï¸ Forward pass tracing ì‹¤íŒ¨: {e}")
    finally:
        # Hook ì œê±°
        for hook in hooks:
            hook.remove()

    return traced_ops

def main():
    parser = argparse.ArgumentParser(description='YOLOv11 Primitive Operator Analyzer v2')
    parser.add_argument('model_path', help='Path to .pt model file')
    parser.add_argument('--trace', action='store_true', help='Enable forward pass tracing')
    parser.add_argument('--no-save', action='store_true', help='Disable report saving')

    args = parser.parse_args()

    if not Path(args.model_path).exists():
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.model_path}")
        sys.exit(1)

    success = analyze_primitive_operators(
        args.model_path,
        trace_forward=args.trace,
        save_report=not args.no_save
    )

    if not success:
        sys.exit(1)

if __name__ == "__main__":
    main()