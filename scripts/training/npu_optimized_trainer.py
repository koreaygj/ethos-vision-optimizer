#!/usr/bin/env python3
"""
NPU ìµœì í™” YOLO ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ (ëª¨ë¸ êµ¬ì¡° í™•ì¸ ê¸°ëŠ¥ ì¶”ê°€)
data/datasetì„ ì‚¬ìš©í•œ ë‹¨ê³„ë³„ NPU ìµœì í™” ëª¨ë¸ í›ˆë ¨
"""

import os
import sys
import torch
import torch.nn as nn
import time
from pathlib import Path
from datetime import datetime
from ultralytics import YOLO
import json
import argparse
import yaml
from collections import Counter, defaultdict

class NPUOptimizedTrainer:
    def __init__(self, pretrained_weights=None, inspect_only=False):
        self.project_root = Path(__file__).parent.parent.parent
        self.data_yaml = self.project_root / "data" / "dataset" / "data.yaml"
        self.models_dir = self.project_root / "models" / "train"
        self.results_dir = self.project_root / "results" / "training"
        self.results_dir.mkdir(parents=True, exist_ok=True)

        # ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì„¤ì •
        self.pretrained_weights = pretrained_weights or 'yolov11n.pt'
        
        # ê²€ì‚¬ ì „ìš© ëª¨ë“œ
        self.inspect_only = inspect_only

        # í›ˆë ¨ ê²°ê³¼ ì €ì¥ìš©
        self.training_results = {}

        # Activation ê²€ì¦ìš©
        self.activation_stats = defaultdict(int)

        # ë””ë°”ì´ìŠ¤ ì„¤ì • (MPS ì§€ì›)
        if torch.backends.mps.is_available():
            self.device = 'mps'
            print("ğŸš€ MPS (Apple Silicon GPU) ê°€ì† ì‚¬ìš©")
            torch.mps.set_per_process_memory_fraction(0.8)
        elif torch.cuda.is_available():
            self.device = 'cuda'
            print("ğŸš€ CUDA GPU ê°€ì† ì‚¬ìš©")
        else:
            self.device = 'cpu'
            print("âš ï¸ CPUë§Œ ì‚¬ìš© (ëŠë¦° í›ˆë ¨)")

    def get_npu_models(self):
        """NPU ìµœì í™” ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        npu_models = {
            'level1': {
                'path': self.models_dir / "npu_level1_scales.yaml",
                'name': 'Level 1: Backbone C3k2 ìµœì í™”',
                'description': 'Backbone C3k2 â†’ C2f ë³€í™˜',
                'epochs': 100,
                'batch': 16,
                'expected_improvement': '15-20%',
                'risk': 'Low'
            },
            'level2-relu': {
                'path': self.models_dir / "npu_level2_scales_backbone_relu.yaml",
                'name': 'Level 2: Backbone + Head ìµœì í™” (ReLU)',
                'description': 'Backbone + Head C3k2 â†’ C2f ë³€í™˜ + ReLU',
                'epochs': 100,
                'batch': 16,
                'expected_improvement': '25-30%',
                'risk': 'Low'
            },
            'level3-relu': {
                'path': self.models_dir / "npu_level3_scales_backbone_head_relu.yaml",
                'name': 'Level 3: + C2PSA ìµœì í™” (ReLU)',
                'description': 'Backbone + Head + C2PSA â†’ CSP + ReLU',
                'epochs': 100,
                'batch': 16,
                'expected_improvement': '35-40%',
                'risk': 'Medium'
            },
            'level4-relu': {
                'path': self.models_dir / "npu_level4_activation_relu.yaml",
                'name': 'Level 4: ì™„ì „ ìµœì í™” (ReLU)',
                'description': 'All optimizations + ReLU',
                'epochs': 100,
                'batch': 16,
                'expected_improvement': '40-45%',
                'risk': 'High'
            },
            'level2-leaky': {
                'path': self.models_dir / "npu_level2_scales_backbone_leaky.yaml",
                'name': 'Level 2: Backbone + Head ìµœì í™” (LeakyReLU)',
                'description': 'Backbone + Head C3k2 â†’ C2f ë³€í™˜ + LeakyReLU',
                'epochs': 100,
                'batch': 16,
                'expected_improvement': '25-30%',
                'risk': 'Low'
            },
            'level3-leaky': {
                'path': self.models_dir / "npu_level3_scales_backbone_head_leaked.yaml",
                'name': 'Level 3: + C2PSA ìµœì í™” (LeakyReLU)',
                'description': 'Backbone + Head + C2PSA â†’ CSP + LeakyReLU',
                'epochs': 100,
                'batch': 16,
                'expected_improvement': '35-40%',
                'risk': 'Medium'
            },
            'level4-leaky': {
                'path': self.models_dir / "npu_level4_activation_leaked.yaml",
                'name': 'Level 4: ì™„ì „ ìµœì í™” (LeakyReLU)',
                'description': 'All optimizations + LeakyReLU',
                'epochs': 100,
                'batch': 16,
                'expected_improvement': '40-45%',
                'risk': 'High'
            }
        }
        return npu_models

    def inspect_yaml_config(self, yaml_path):
        """YAML íŒŒì¼ ë‚´ìš© ê²€ì‚¬ ë° ì¶œë ¥"""
        print(f"\n{'='*80}")
        print(f"ğŸ“„ YAML ì„¤ì • íŒŒì¼ ê²€ì‚¬: {yaml_path.name}")
        print(f"{'='*80}")
        
        try:
            with open(yaml_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            print(f"\nâœ… YAML íŒŒì¼ ë¡œë“œ ì„±ê³µ")
            
            # ê¸°ë³¸ ì •ë³´
            print(f"\nğŸ” ê¸°ë³¸ ì„¤ì •:")
            print(f"   - í´ë˜ìŠ¤ ìˆ˜: {config.get('nc', 'N/A')}")
            if 'scales' in config:
                print(f"   - ìŠ¤ì¼€ì¼: {list(config['scales'].keys())}")
            
            # Backbone ê²€ì‚¬
            if 'backbone' in config:
                print(f"\nğŸ§± Backbone êµ¬ì¡° ({len(config['backbone'])} ë ˆì´ì–´):")
                self._print_layers(config['backbone'], 'Backbone')
            
            # Head ê²€ì‚¬
            if 'head' in config:
                print(f"\nğŸ¯ Head êµ¬ì¡° ({len(config['head'])} ë ˆì´ì–´):")
                self._print_layers(config['head'], 'Head')
            
            # Activation í•¨ìˆ˜ ë¶„ì„
            self._analyze_activations(config)
            
            return config
            
        except Exception as e:
            print(f"âŒ YAML íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def _print_layers(self, layers, section_name):
        """ë ˆì´ì–´ ì •ë³´ ì¶œë ¥"""
        activation_counts = {}
        module_counts = {}
        
        for idx, layer in enumerate(layers):
            # ë”•ì…”ë„ˆë¦¬ í˜•ì‹ê³¼ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ ëª¨ë‘ ì§€ì›
            if isinstance(layer, dict):
                from_val = layer.get('from', 'N/A')
                module = layer.get('module', 'N/A')
                args = layer.get('args', [])
                activation = layer.get('activation', 'Default')
                repeats = layer.get('repeats', 1)
            else:
                # ë¦¬ìŠ¤íŠ¸ í˜•ì‹ [from, repeats, module, args, ...]
                from_val = layer[0] if len(layer) > 0 else 'N/A'
                repeats = layer[1] if len(layer) > 1 else 1
                module = layer[2] if len(layer) > 2 else 'N/A'
                args = layer[3] if len(layer) > 3 else []
                activation = layer[4] if len(layer) > 4 else 'Default'
            
            # í†µê³„ ì§‘ê³„
            activation_counts[activation] = activation_counts.get(activation, 0) + 1
            module_counts[module] = module_counts.get(module, 0) + 1
            
            # ë ˆì´ì–´ ì •ë³´ ì¶œë ¥ (ì²˜ìŒ 5ê°œì™€ ë§ˆì§€ë§‰ 2ê°œë§Œ)
            if idx < 5 or idx >= len(layers) - 2:
                print(f"   [{idx:2d}] {module:15s} | from: {str(from_val):8s} | "
                      f"repeats: {repeats} | activation: {activation}")
            elif idx == 5:
                print(f"   ... ({len(layers) - 7} more layers) ...")
        
        # í†µê³„ ì¶œë ¥
        print(f"\n   ğŸ“Š {section_name} í†µê³„:")
        print(f"      ëª¨ë“ˆ ë¶„í¬: {dict(module_counts)}")
        print(f"      í™œì„±í™” í•¨ìˆ˜: {dict(activation_counts)}")

    def _analyze_activations(self, config):
        """í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš© ë¶„ì„"""
        print(f"\nğŸ”¥ í™œì„±í™” í•¨ìˆ˜ ë¶„ì„:")
        
        all_activations = []
        
        # Backbone í™œì„±í™” í•¨ìˆ˜ ìˆ˜ì§‘
        if 'backbone' in config:
            for layer in config['backbone']:
                if isinstance(layer, dict) and 'activation' in layer:
                    all_activations.append(layer['activation'])
                elif isinstance(layer, list) and len(layer) > 4:
                    all_activations.append(layer[4])
        
        # Head í™œì„±í™” í•¨ìˆ˜ ìˆ˜ì§‘
        if 'head' in config:
            for layer in config['head']:
                if isinstance(layer, dict) and 'activation' in layer:
                    all_activations.append(layer['activation'])
                elif isinstance(layer, list) and len(layer) > 4:
                    all_activations.append(layer[4])
        
        # í†µê³„ ì¶œë ¥
        activation_stats = {}
        for act in all_activations:
            activation_stats[act] = activation_stats.get(act, 0) + 1
        
        total = len(all_activations)
        if total > 0:
            for act, count in sorted(activation_stats.items(), key=lambda x: -x[1]):
                percentage = (count / total) * 100
                print(f"   - {act}: {count}ê°œ ({percentage:.1f}%)")
        else:
            print(f"   âš ï¸ ëª…ì‹œì  í™œì„±í™” í•¨ìˆ˜ ì—†ìŒ (ëª¨ë“ˆ ê¸°ë³¸ê°’ ì‚¬ìš©)")

    def inspect_model_structure(self, model, level_name):
        """ì´ˆê¸°í™”ëœ ëª¨ë¸ êµ¬ì¡° ê²€ì‚¬ ë° ì¶œë ¥"""
        print(f"\n{'='*80}")
        print(f"ğŸ” ëª¨ë¸ êµ¬ì¡° ê²€ì‚¬: {level_name}")
        print(f"{'='*80}")
        
        try:
            print(f"\nğŸ“ ëª¨ë¸ ì•„í‚¤í…ì²˜:")
            print(model.model)
            
            print(f"\nğŸ“Š ëª¨ë¸ í†µê³„:")
            # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
            total_params = sum(p.numel() for p in model.model.parameters())
            trainable_params = sum(p.numel() for p in model.model.parameters() if p.requires_grad)
            
            print(f"   - ì´ íŒŒë¼ë¯¸í„°: {total_params:,}")
            print(f"   - í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}")
            print(f"   - ëª¨ë¸ í¬ê¸°: {total_params * 4 / 1024 / 1024:.2f} MB (FP32 ê¸°ì¤€)")
            
            # Glennì˜ ë°©ì‹ìœ¼ë¡œ í™œì„±í™” í•¨ìˆ˜ ê²€ì¦
            activation_verification = self.verify_model_activations(model)

            print(f"\nğŸ”¥ í™œì„±í™” í•¨ìˆ˜ ê²€ì¦ ê²°ê³¼:")
            if activation_verification['total_found'] > 0:
                print(f"   âœ… ì´ {activation_verification['total_found']}ê°œì˜ í™œì„±í™” í•¨ìˆ˜ ë°œê²¬")
                for act_type, count in activation_verification['stats'].items():
                    print(f"   - {act_type}: {count}ê°œ")
            else:
                print("   âš ï¸ ëª…ì‹œì  í™œì„±í™” í•¨ìˆ˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                print("   ì „ì—­ í™œì„±í™” ì„¤ì •ì´ ì‚¬ìš© ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # ë ˆì´ì–´ íƒ€ì… í†µê³„
            print(f"\nğŸ“¦ ë ˆì´ì–´ íƒ€ì… ë¶„í¬:")
            layer_types = {}
            for name, module in model.model.named_modules():
                module_type = type(module).__name__
                if module_type != 'Sequential' and module_type != 'ModuleList':
                    layer_types[module_type] = layer_types.get(module_type, 0) + 1
            
            for layer_type, count in sorted(layer_types.items(), key=lambda x: -x[1])[:10]:
                print(f"   - {layer_type}: {count}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ êµ¬ì¡° ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            return False

    def train_model(self, model_config, level_name):
        """ê°œë³„ ëª¨ë¸ í›ˆë ¨ (ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì§€ì›)"""
        print(f"\nğŸ¯ {model_config['name']} í›ˆë ¨ ì‹œì‘")
        print(f"ğŸ“ ì„¤ëª…: {model_config['description']}")
        print(f"âš¡ ì˜ˆìƒ ê°œì„ : {model_config['expected_improvement']}")
        print(f"âš ï¸ ìœ„í—˜ë„: {model_config['risk']}")
        print(f"ğŸ”„ ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜: {self.pretrained_weights if self.pretrained_weights else 'ì—†ìŒ (ëœë¤ ì´ˆê¸°í™”)'}")
        print("=" * 60)

        # 1. YAML ì„¤ì • ê²€ì‚¬
        yaml_config = self.inspect_yaml_config(model_config['path'])
        if not yaml_config:
            return None

        # ëª¨ë¸ ì´ˆê¸°í™” ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
        try:
            # 2. ì»¤ìŠ¤í…€ ì•„í‚¤í…ì²˜ ë¡œë“œ
            model = YOLO(model_config['path'])
            print(f"\nâœ… ì»¤ìŠ¤í…€ êµ¬ì¡° ë¡œë“œ: {model_config['path'].name}")

            # 3. ëª¨ë¸ êµ¬ì¡° ê²€ì‚¬
            self.inspect_model_structure(model, level_name)

            # ê²€ì‚¬ ì „ìš© ëª¨ë“œë©´ ì—¬ê¸°ì„œ ì¢…ë£Œ
            if self.inspect_only:
                print(f"\nâœ… ëª¨ë¸ ê²€ì‚¬ ì™„ë£Œ (í›ˆë ¨ ìŠ¤í‚µ)")
                return {
                    'level': level_name,
                    'model_name': model_config['name'],
                    'status': 'inspected',
                    'yaml_config': yaml_config
                }

            # 4. ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹œë„
            if self.pretrained_weights:
                try:
                    pretrained_path = Path(self.pretrained_weights)

                    if not pretrained_path.is_absolute():
                        if pretrained_path.suffix == '.pt' and len(pretrained_path.parts) == 1:
                            model.load(self.pretrained_weights)
                        else:
                            pretrained_path = self.project_root / self.pretrained_weights
                            if pretrained_path.exists():
                                model.load(str(pretrained_path))
                            else:
                                raise FileNotFoundError(f"Pretrained weights not found: {pretrained_path}")
                    else:
                        if pretrained_path.exists():
                            model.load(str(pretrained_path))
                        else:
                            raise FileNotFoundError(f"Pretrained weights not found: {pretrained_path}")

                    print(f"\nâœ… ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ: {self.pretrained_weights}")
                    print(f"   ğŸ“ˆ ìˆ˜ë ´ ì†ë„ í–¥ìƒ ë° ë” ë‚˜ì€ ì´ˆê¸° ì„±ëŠ¥ ê¸°ëŒ€")

                except Exception as e:
                    print(f"\nâš ï¸ ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    print(f"   ğŸ“ ëœë¤ ì´ˆê¸°í™”ë¡œ ì§„í–‰ (í›ˆë ¨ ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)")
            else:
                print(f"\nğŸ“ ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì—†ì´ ëœë¤ ì´ˆê¸°í™”ë¡œ ì§„í–‰")

        except Exception as e:
            print(f"\nâŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None

        # ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì‹œ í•™ìŠµë¥  ì¡°ì •
        lr0 = 0.003 if self.pretrained_weights else 0.005

        # í›ˆë ¨ íŒŒë¼ë¯¸í„° ì„¤ì •
        train_args = {
            'data': str(self.data_yaml),
            'epochs': model_config['epochs'],
            'batch': model_config['batch'],
            'imgsz': 640,
            'device': self.device,
            'project': str(self.results_dir),
            'name': f"{level_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'save_period': 10,
            'val': True,
            'plots': True,
            'verbose': True,

            # NPU ì¹œí™”ì  í›ˆë ¨ ì„¤ì •
            'optimizer': 'SGD',
            'lr0': lr0,
            'lrf': 0.1,
            'momentum': 0.9,
            'weight_decay': 0.001,
            'warmup_epochs': 5.0,
            'patience': 25,
            'amp': False,
            'deterministic': True,

            # NPU í˜¸í™˜ ë°ì´í„° ì¦ê°•
            'hsv_h': 0.01,
            'hsv_s': 0.5,
            'hsv_v': 0.3,
            'degrees': 0.0,
            'translate': 0.05,
            'scale': 0.2,
            'shear': 0.0,
            'perspective': 0.0,
            'flipud': 0.0,
            'fliplr': 0.5,
            'mosaic': 0.0,
            'mixup': 0.0,
            'copy_paste': 0.0,
            'auto_augment': '',
            'erasing': 0.0,
        }

        print(f"\nğŸ‹ï¸ í›ˆë ¨ ì‹œì‘...")
        print(f"   ğŸ“Š Epochs: {train_args['epochs']}")
        print(f"   ğŸ“¦ Batch: {train_args['batch']}")
        print(f"   ğŸ–¥ï¸ Device: {train_args['device']}")
        print(f"   ğŸ“ˆ Learning Rate: {lr0} ({'Pretrained' if self.pretrained_weights else 'Random Init'})")

        start_time = time.time()

        try:
            results = model.train(**train_args)
            training_time = time.time() - start_time

            result_data = {
                'level': level_name,
                'model_name': model_config['name'],
                'model_path': str(model_config['path']),
                'pretrained_weights': self.pretrained_weights,
                'status': 'success',
                'training_time_seconds': training_time,
                'training_time_formatted': f"{training_time/3600:.1f}h {(training_time%3600)/60:.1f}m",
                'epochs_completed': train_args['epochs'],
                'batch_size': train_args['batch'],
                'device_used': train_args['device'],
                'learning_rate': lr0,
                'expected_improvement': model_config['expected_improvement'],
                'risk_level': model_config['risk'],
                'best_model_path': str(results.save_dir / 'weights' / 'best.pt') if hasattr(results, 'save_dir') else None,
                'last_model_path': str(results.save_dir / 'weights' / 'last.pt') if hasattr(results, 'save_dir') else None,
                'metrics': self.extract_metrics(results) if results else None,
                'yaml_config': yaml_config
            }

            print(f"\nâœ… {level_name} í›ˆë ¨ ì™„ë£Œ!")
            print(f"â±ï¸ í›ˆë ¨ ì‹œê°„: {result_data['training_time_formatted']}")
            if result_data['best_model_path']:
                print(f"ğŸ’¾ ìµœê³  ëª¨ë¸: {result_data['best_model_path']}")

            return result_data

        except Exception as e:
            print(f"\nâŒ {level_name} í›ˆë ¨ ì‹¤íŒ¨: {e}")
            return {
                'level': level_name,
                'model_name': model_config['name'],
                'pretrained_weights': self.pretrained_weights,
                'status': 'failed',
                'error': str(e),
                'training_time_seconds': time.time() - start_time,
                'yaml_config': yaml_config
            }

    def extract_metrics(self, results):
        """í›ˆë ¨ ê²°ê³¼ì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ"""
        try:
            if hasattr(results, 'results_dict'):
                return results.results_dict
            elif hasattr(results, 'metrics'):
                return results.metrics
            else:
                return {"note": "Metrics extraction not available"}
        except:
            return {"note": "Metrics extraction failed"}

    def inspect_all_models(self):
        """ëª¨ë“  ëª¨ë¸ êµ¬ì¡°ë§Œ ê²€ì‚¬ (í›ˆë ¨ ì—†ì´)"""
        npu_models = self.get_npu_models()
        
        print(f"\n{'='*80}")
        print(f"ğŸ” ëª¨ë“  NPU ìµœì í™” ëª¨ë¸ ê²€ì‚¬ ëª¨ë“œ")
        print(f"{'='*80}")
        
        inspection_results = {}
        
        for level, model_config in npu_models.items():
            if not model_config['path'].exists():
                print(f"\nâŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_config['path']}")
                continue
            
            try:
                # YAML ê²€ì‚¬
                yaml_config = self.inspect_yaml_config(model_config['path'])
                
                # ëª¨ë¸ ì´ˆê¸°í™” ë° êµ¬ì¡° ê²€ì‚¬
                model = YOLO(model_config['path'])
                self.inspect_model_structure(model, level)
                
                inspection_results[level] = {
                    'name': model_config['name'],
                    'status': 'success',
                    'yaml_config': yaml_config
                }
                
            except Exception as e:
                print(f"\nâŒ {level} ê²€ì‚¬ ì‹¤íŒ¨: {e}")
                inspection_results[level] = {
                    'name': model_config['name'],
                    'status': 'failed',
                    'error': str(e)
                }
        
        # ê²€ì‚¬ ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        json_path = self.results_dir / f"model_inspection_{timestamp}.json"
        with open(json_path, 'w') as f:
            json.dump(inspection_results, f, indent=2, default=str)
        
        print(f"\n\nğŸ“Š ê²€ì‚¬ ê²°ê³¼ ì €ì¥: {json_path}")
        return inspection_results

    def train_all_levels(self, levels=None):
        """ëª¨ë“  ë ˆë²¨ ë˜ëŠ” ì§€ì •ëœ ë ˆë²¨ë“¤ í›ˆë ¨"""
        npu_models = self.get_npu_models()

        if levels is None:
            levels = list(npu_models.keys())

        print(f"\nğŸš€ NPU ìµœì í™” ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        print(f"ğŸ“‚ ë°ì´í„°ì…‹: {self.data_yaml}")
        print(f"ğŸ¯ í›ˆë ¨ ë ˆë²¨: {', '.join(levels)}")
        print(f"ğŸ”„ ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜: {self.pretrained_weights if self.pretrained_weights else 'ì—†ìŒ'}")
        print(f"ğŸ“Š ê²°ê³¼ ì €ì¥: {self.results_dir}")
        print(f"ğŸ” ê²€ì‚¬ ì „ìš© ëª¨ë“œ: {'ì˜ˆ' if self.inspect_only else 'ì•„ë‹ˆì˜¤'}")
        print("=" * 80)

        for level in levels:
            if level not in npu_models:
                print(f"\nâš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë ˆë²¨: {level}")
                continue

            model_config = npu_models[level]

            if not model_config['path'].exists():
                print(f"\nâŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_config['path']}")
                continue

            result = self.train_model(model_config, level)
            if result:
                self.training_results[level] = result

        if not self.inspect_only:
            self.save_training_summary()

    def train_single_level(self, level):
        """ë‹¨ì¼ ë ˆë²¨ë§Œ í›ˆë ¨"""
        self.train_all_levels(levels=[level])

    def save_training_summary(self):
        """í›ˆë ¨ ê²°ê³¼ ìš”ì•½ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        json_path = self.results_dir / f"npu_training_summary_{timestamp}.json"
        with open(json_path, 'w') as f:
            json.dump(self.training_results, f, indent=2, default=str)

        md_path = self.results_dir / f"NPU_TRAINING_REPORT_{timestamp}.md"
        self.generate_markdown_report(md_path)

        print(f"\nğŸ“Š í›ˆë ¨ ê²°ê³¼ ì €ì¥:")
        print(f"   ğŸ“„ JSON: {json_path}")
        print(f"   ğŸ“ Report: {md_path}")

    def generate_markdown_report(self, output_path):
        """ë§ˆí¬ë‹¤ìš´ í›ˆë ¨ ë¦¬í¬íŠ¸ ìƒì„±"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        report = f"""# NPU ìµœì í™” ëª¨ë¸ í›ˆë ¨ ê²°ê³¼ ë¦¬í¬íŠ¸

**ìƒì„±ì¼**: {timestamp}
**ë°ì´í„°ì…‹**: Traffic Sign Detection (15 classes)
**ì´ í›ˆë ¨ ë ˆë²¨**: {len(self.training_results)}ê°œ
**ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜**: {self.pretrained_weights if self.pretrained_weights else 'ì—†ìŒ (ëœë¤ ì´ˆê¸°í™”)'}

## ğŸ“Š í›ˆë ¨ ê²°ê³¼ ìš”ì•½

| Level | ëª¨ë¸ëª… | ìƒíƒœ | í›ˆë ¨ì‹œê°„ | í•™ìŠµë¥  | ì˜ˆìƒê°œì„  | ìœ„í—˜ë„ |
|-------|--------|------|----------|--------|----------|--------|
"""

        for level, result in self.training_results.items():
            status_emoji = "âœ…" if result['status'] == 'success' else ("ğŸ”" if result['status'] == 'inspected' else "âŒ")
            training_time = result.get('training_time_formatted', 'N/A')
            learning_rate = result.get('learning_rate', 'N/A')
            expected_improvement = result.get('expected_improvement', 'N/A')
            risk = result.get('risk_level', 'N/A')

            report += f"| {level.upper()} | {result['model_name']} | {status_emoji} {result['status']} | {training_time} | {learning_rate} | {expected_improvement} | {risk} |\n"

        successful_trainings = {k: v for k, v in self.training_results.items() if v['status'] == 'success'}

        if successful_trainings:
            report += f"\n## ğŸ¯ ì„±ê³µí•œ í›ˆë ¨ ìƒì„¸ ì •ë³´\n"
            for level, result in successful_trainings.items():
                report += f"\n### {level.upper()}: {result['model_name']}\n\n"
                report += f"- **ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜**: {result.get('pretrained_weights', 'ì—†ìŒ')}\n"
                report += f"- **í›ˆë ¨ ì‹œê°„**: {result['training_time_formatted']}\n"
                report += f"- **ìµœê³  ëª¨ë¸**: `{result.get('best_model_path', 'N/A')}`\n\n"

        report += "\n---\n**ğŸ’¡ ì°¸ê³ **: ì´ ë¦¬í¬íŠ¸ëŠ” ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n"

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)

    def get_activation_name(self, activation) -> str:
        """Get human-readable activation function name"""
        if activation is None:
            return "None"

        activation_names = {
            nn.ReLU: "ReLU",
            nn.LeakyReLU: "LeakyReLU",
            nn.ELU: "ELU",
            nn.ReLU6: "ReLU6",
            nn.PReLU: "PReLU",
            nn.GELU: "GELU",
            nn.SiLU: "SiLU",
            nn.Sigmoid: "Sigmoid",
            nn.Tanh: "Tanh",
            nn.Hardswish: "Hardswish",
            nn.Mish: "Mish"
        }

        for act_type, name in activation_names.items():
            if isinstance(activation, act_type):
                return name

        return str(type(activation).__name__)

    def verify_model_activations(self, model) -> dict:
        """
        Verify activation functions in a loaded model
        Implementation of Glenn's suggestion from GitHub issue
        """
        print("ğŸ” Verifying activation functions in model...")

        # Reset stats
        self.activation_stats.clear()
        activation_layers = []

        def analyze_module(module, name="", level=0):
            """Recursively analyze activation functions"""
            for child_name, child_module in module.named_children():
                full_name = f"{name}.{child_name}" if name else child_name

                # Direct activation function detection
                if isinstance(child_module, (nn.ReLU, nn.LeakyReLU, nn.ELU, nn.ReLU6,
                                           nn.PReLU, nn.GELU, nn.SiLU, nn.Sigmoid,
                                           nn.Tanh, nn.Hardswish, nn.Mish)):
                    activation_name = self.get_activation_name(child_module)
                    self.activation_stats[activation_name] += 1
                    activation_layers.append({
                        'name': full_name,
                        'type': activation_name,
                        'module': str(type(child_module).__name__),
                        'level': level
                    })

                    # Glenn's debug statement implementation
                    print(f"   âœ… Found {activation_name} at: {full_name}")

                # Check modules with embedded activations
                elif hasattr(child_module, 'act') or hasattr(child_module, 'activation'):
                    act_func = getattr(child_module, 'act', None) or getattr(child_module, 'activation', None)
                    if act_func is not None:
                        activation_name = self.get_activation_name(act_func)
                        self.activation_stats[activation_name] += 1
                        activation_layers.append({
                            'name': full_name,
                            'type': f"{str(type(child_module).__name__)}({activation_name})",
                            'module': str(type(child_module).__name__),
                            'level': level,
                            'embedded': True
                        })
                        print(f"   âœ… Found embedded {activation_name} in: {full_name}")

                # Recursively check children
                if len(list(child_module.children())) > 0:
                    analyze_module(child_module, full_name, level + 1)

        # Analyze the model
        analyze_module(model.model)

        # Print summary (Glenn's suggestion)
        print("\nğŸ“Š Activation Function Analysis Results:")
        print("=" * 50)

        if self.activation_stats:
            for activation, count in sorted(self.activation_stats.items()):
                print(f"   {activation}: {count} instances")

                # Glenn's verification check
                if activation == "ReLU":
                    print(f"   âœ… ReLU verification: {count > 0}")
                elif activation == "LeakyReLU":
                    print(f"   âœ… LeakyReLU verification: {count > 0}")
        else:
            print("   âš ï¸ No explicit activation functions detected!")
            print("   This might indicate global activation setting is used.")

        # Check for global activation setting
        try:
            if hasattr(model, 'cfg') and model.cfg:
                if isinstance(model.cfg, dict) and 'act' in model.cfg:
                    global_act = model.cfg['act']
                    print(f"   ğŸŒ Global activation detected: {global_act}")
                    self.activation_stats[f"Global-{global_act}"] += 1
        except Exception as e:
            print(f"   âš ï¸ Could not check global activation: {e}")

        return {
            'stats': dict(self.activation_stats),
            'layers': activation_layers,
            'total_found': sum(self.activation_stats.values())
        }

    def compare_activation_training_results(self, results_dict: dict):
        """
        Compare training results to detect if different activations yield identical results
        (Glenn's main concern from the GitHub issue)
        """
        print("\nğŸ”„ Comparing activation function training results...")

        # Group results by activation type
        activation_groups = defaultdict(list)

        for level, result in results_dict.items():
            if 'activation_verification' in result:
                primary_activation = max(result['activation_verification']['stats'].items(),
                                       key=lambda x: x[1], default=('Unknown', 0))[0]
                activation_groups[primary_activation].append((level, result))

        # Check for identical results (Glenn's issue)
        print("ğŸ“Š Results by activation function:")
        for activation, level_results in activation_groups.items():
            print(f"\n   {activation}:")
            for level, result in level_results:
                status = result.get('status', 'unknown')
                training_time = result.get('training_time_formatted', 'N/A')
                print(f"     - {level}: {status} (time: {training_time})")

        # Warning for identical results
        if len(activation_groups) > 1:
            print("\nâš ï¸ Multiple activation types detected.")
            print("   If training results are identical, this might indicate:")
            print("   1. Global activation setting overriding individual settings")
            print("   2. Model configuration not properly applied")
            print("   3. Dataset characteristics don't emphasize activation differences")
            print("   4. Other hyperparameters dominating the training process")

def main():
    parser = argparse.ArgumentParser(description='NPU ìµœì í™” YOLO ëª¨ë¸ í›ˆë ¨ (ëª¨ë¸ ê²€ì‚¬ ê¸°ëŠ¥ ì¶”ê°€)')
    parser.add_argument('--level', type=str, 
                       choices=['level1', 'level2-relu', 'level3-relu', 'level4-relu', 
                               'level2-leaky', 'level3-leaky', 'level4-leaky'],
                       help='íŠ¹ì • ë ˆë²¨ë§Œ í›ˆë ¨')
    parser.add_argument('--levels', type=str, nargs='+',
                       choices=['level1', 'level2-relu', 'level3-relu', 'level4-relu',
                               'level2-leaky', 'level3-leaky', 'level4-leaky'],
                       help='ì—¬ëŸ¬ ë ˆë²¨ ì„ íƒ')
    parser.add_argument('--pretrained', type=str, default='yolov11n.pt',
                       help='ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ê²½ë¡œ (ê¸°ë³¸ê°’: yolov11n.pt)')
    parser.add_argument('--no-pretrained', action='store_true',
                       help='ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ')
    parser.add_argument('--inspect', action='store_true',
                       help='ëª¨ë¸ êµ¬ì¡°ë§Œ ê²€ì‚¬ (í›ˆë ¨ ì•ˆí•¨)')
    parser.add_argument('--inspect-all', action='store_true',
                       help='ëª¨ë“  ëª¨ë¸ êµ¬ì¡° ê²€ì‚¬ (í›ˆë ¨ ì•ˆí•¨)')

    args = parser.parse_args()

    # ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì„¤ì •
    pretrained_weights = None if args.no_pretrained else args.pretrained
    
    # ê²€ì‚¬ ì „ìš© ëª¨ë“œ ì„¤ì •
    inspect_only = args.inspect or args.inspect_all

    trainer = NPUOptimizedTrainer(pretrained_weights=pretrained_weights, inspect_only=inspect_only)

    # ëª¨ë“œë³„ ì‹¤í–‰
    if args.inspect_all:
        print("ğŸ” ëª¨ë“  ëª¨ë¸ ê²€ì‚¬ ëª¨ë“œ")
        trainer.inspect_all_models()
    elif args.inspect:
        if args.level:
            print(f"ğŸ” {args.level} ëª¨ë¸ ê²€ì‚¬ ëª¨ë“œ")
            trainer.train_single_level(args.level)
        elif args.levels:
            print(f"ğŸ” ì„ íƒëœ ëª¨ë¸ë“¤ ê²€ì‚¬ ëª¨ë“œ: {', '.join(args.levels)}")
            trainer.train_all_levels(levels=args.levels)
        else:
            print("âš ï¸ --inspect ì‚¬ìš© ì‹œ --level ë˜ëŠ” --levels ì§€ì • í•„ìš”")
            print("   ë˜ëŠ” --inspect-all ì‚¬ìš©")
    else:
        # ì¼ë°˜ í›ˆë ¨ ëª¨ë“œ
        if pretrained_weights:
            print(f"ğŸ“¦ ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜: {pretrained_weights}")
            print(f"   âš¡ ë¹ ë¥¸ ìˆ˜ë ´ ë° ë” ë‚˜ì€ ì´ˆê¸° ì„±ëŠ¥ ê¸°ëŒ€")
        else:
            print(f"âš ï¸ ëœë¤ ì´ˆê¸°í™” ëª¨ë“œ (í›ˆë ¨ ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)")

        if args.level:
            print(f"ğŸ¯ ë‹¨ì¼ ë ˆë²¨ í›ˆë ¨: {args.level}")
            trainer.train_single_level(args.level)
        elif args.levels:
            print(f"ğŸ¯ ì„ íƒëœ ë ˆë²¨ë“¤ í›ˆë ¨: {', '.join(args.levels)}")
            trainer.train_all_levels(levels=args.levels)
        else:
            print("ğŸ¯ ëª¨ë“  ë ˆë²¨ ìˆœì°¨ í›ˆë ¨")
            trainer.train_all_levels()

    print("\nğŸ‰ ì™„ë£Œ!")

if __name__ == "__main__":
    main()