#!/usr/bin/env python3
"""
NPU ìµœì í™” YOLO ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ (ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì§€ì› ë²„ì „)
data/datasetì„ ì‚¬ìš©í•œ ë‹¨ê³„ë³„ NPU ìµœì í™” ëª¨ë¸ í›ˆë ¨
"""

import os
import sys
import torch
import time
from pathlib import Path
from datetime import datetime
from ultralytics import YOLO
import json
import argparse

class NPUOptimizedTrainer:
    def __init__(self, pretrained_weights=None):
        self.project_root = Path(__file__).parent.parent.parent
        self.data_yaml = self.project_root / "data" / "dataset" / "data.yaml"
        self.models_dir = self.project_root / "models" / "train"
        self.results_dir = self.project_root / "results" / "training"
        self.results_dir.mkdir(parents=True, exist_ok=True)

        # ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì„¤ì •
        self.pretrained_weights = pretrained_weights or 'yolov11n.pt'

        # í›ˆë ¨ ê²°ê³¼ ì €ì¥ìš©
        self.training_results = {}

        # ë””ë°”ì´ìŠ¤ ì„¤ì • (MPS ì§€ì›)
        if torch.backends.mps.is_available():
            self.device = 'mps'
            print("ğŸš€ MPS (Apple Silicon GPU) ê°€ì† ì‚¬ìš©")
            # MPS ë©”ëª¨ë¦¬ ìµœì í™”
            torch.mps.set_per_process_memory_fraction(0.8)
        elif torch.cuda.is_available():
            self.device = 'cuda'
            print("ğŸš€ CUDA GPU ê°€ì† ì‚¬ìš©")
        else:
            self.device = 'cpu'
            print("âš ï¸ CPUë§Œ ì‚¬ìš© (ëŠë¦° í›ˆë ¨)")

    def get_npu_models(self):
        """NPU ìµœì í™” ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        npu_models = {
            'level1': {
                'path': self.models_dir / "npu_level1_scales.yaml",
                'name': 'Level 1: Backbone C3k2 ìµœì í™”',
                'description': 'Backbone C3k2 â†’ C2f ë³€í™˜',
                'epochs': 100,
                'batch': 16,
                'expected_improvement': '15-20%',
                'risk': 'Low'
            },
            'level2': {
                'path': self.models_dir / "npu_level2_scales_backbone.yaml",
                'name': 'Level 2: Backbone + Head ìµœì í™”',
                'description': 'Backbone + Head C3k2 â†’ C2f ë³€í™˜',
                'epochs': 100,
                'batch': 16,
                'expected_improvement': '25-30%',
                'risk': 'Low'
            },
            'level3': {
                'path': self.models_dir / "npu_level3_scales_backbone_head.yaml",
                'name': 'Level 3: + C2PSA ìµœì í™”',
                'description': 'Backbone + Head + C2PSA â†’ CSP',
                'epochs': 100,
                'batch': 16,
                'expected_improvement': '35-40%',
                'risk': 'Medium'
            },
            'level4': {
                'path': self.models_dir / "npu_level4_full_optimization.yaml",
                'name': 'Level 4: ì™„ì „ ìµœì í™”',
                'description': 'All optimizations + ConvTranspose2d',
                'epochs': 100,
                'batch': 16,
                'expected_improvement': '40-45%',
                'risk': 'High'
            }
        }
        return npu_models

    def train_model(self, model_config, level_name):
        """ê°œë³„ ëª¨ë¸ í›ˆë ¨ (ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì§€ì›)"""
        print(f"\\nğŸ¯ {model_config['name']} í›ˆë ¨ ì‹œì‘")
        print(f"ğŸ“ ì„¤ëª…: {model_config['description']}")
        print(f"âš¡ ì˜ˆìƒ ê°œì„ : {model_config['expected_improvement']}")
        print(f"âš ï¸ ìœ„í—˜ë„: {model_config['risk']}")
        print(f"ğŸ”„ ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜: {self.pretrained_weights if self.pretrained_weights else 'ì—†ìŒ (ëœë¤ ì´ˆê¸°í™”)'}")
        print("=" * 60)

        # ëª¨ë¸ ì´ˆê¸°í™” ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
        try:
            # 1. ì»¤ìŠ¤í…€ ì•„í‚¤í…ì²˜ ë¡œë“œ
            model = YOLO(model_config['path'])
            print(f"âœ… ì»¤ìŠ¤í…€ êµ¬ì¡° ë¡œë“œ: {model_config['path'].name}")

            # 2. ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹œë„
            if self.pretrained_weights:
                try:
                    pretrained_path = Path(self.pretrained_weights)

                    # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                    if not pretrained_path.is_absolute():
                        # Ultralytics ê¸°ë³¸ ëª¨ë¸ë“¤ (yolov11n.pt ë“±) ë˜ëŠ” í”„ë¡œì íŠ¸ ë‚´ ê²½ë¡œ
                        if pretrained_path.suffix == '.pt' and len(pretrained_path.parts) == 1:
                            # Ultralytics ê¸°ë³¸ ëª¨ë¸ (ìë™ ë‹¤ìš´ë¡œë“œ)
                            model.load(self.pretrained_weights)
                        else:
                            # í”„ë¡œì íŠ¸ ë‚´ ìƒëŒ€ ê²½ë¡œ
                            pretrained_path = self.project_root / self.pretrained_weights
                            if pretrained_path.exists():
                                model.load(str(pretrained_path))
                            else:
                                raise FileNotFoundError(f"Pretrained weights not found: {pretrained_path}")
                    else:
                        # ì ˆëŒ€ ê²½ë¡œ
                        if pretrained_path.exists():
                            model.load(str(pretrained_path))
                        else:
                            raise FileNotFoundError(f"Pretrained weights not found: {pretrained_path}")

                    print(f"âœ… ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ: {self.pretrained_weights}")
                    print(f"   ğŸ“ˆ ìˆ˜ë ´ ì†ë„ í–¥ìƒ ë° ë” ë‚˜ì€ ì´ˆê¸° ì„±ëŠ¥ ê¸°ëŒ€")

                except Exception as e:
                    print(f"âš ï¸ ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    print(f"   ğŸ“ ëœë¤ ì´ˆê¸°í™”ë¡œ ì§„í–‰ (í›ˆë ¨ ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)")
            else:
                print(f"ğŸ“ ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì—†ì´ ëœë¤ ì´ˆê¸°í™”ë¡œ ì§„í–‰")

        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None

        # ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì‹œ í•™ìŠµë¥  ì¡°ì •
        lr0 = 0.003 if self.pretrained_weights else 0.005

        # í›ˆë ¨ íŒŒë¼ë¯¸í„° ì„¤ì •
        train_args = {
            'data': str(self.data_yaml),
            'epochs': model_config['epochs'],
            'batch': model_config['batch'],
            'imgsz': 640,
            'device': self.device,
            'project': str(self.results_dir),
            'name': f"{level_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'save_period': 10,
            'val': True,
            'plots': True,
            'verbose': True,

            # NPU ì¹œí™”ì  í›ˆë ¨ ì„¤ì • (ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ê³ ë ¤)
            'optimizer': 'SGD',          # ì–‘ìí™” ì¹œí™”ì 
            'lr0': lr0,                  # ì‚¬ì „ í›ˆë ¨ ì‹œ ë‚®ì€ í•™ìŠµë¥ 
            'lrf': 0.1,                  # ìµœì¢… í•™ìŠµë¥ 
            'momentum': 0.9,             # SGD ìµœì  ëª¨ë©˜í…€
            'weight_decay': 0.001,       # ê°•í•œ ì •ê·œí™”
            'warmup_epochs': 5.0,        # ì¶©ë¶„í•œ ì›Œë°ì—…
            'patience': 25,              # ì¡°ê¸° ì¢…ë£Œ
            'amp': False,                # Mixed Precision OFF (ì–‘ìí™” ì¤€ë¹„)
            'deterministic': True,       # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼

            # NPU í˜¸í™˜ ë°ì´í„° ì¦ê°•
            'hsv_h': 0.01,       # ìµœì†Œ Hue ë³€í™”
            'hsv_s': 0.5,        # ì ë‹¹í•œ ì±„ë„ ë³€í™”
            'hsv_v': 0.3,        # ìµœì†Œ ë°ê¸° ë³€í™”
            'degrees': 0.0,      # íšŒì „ ë¹„í™œì„±í™”
            'translate': 0.05,   # ìµœì†Œ ì´ë™
            'scale': 0.2,        # ìµœì†Œ ìŠ¤ì¼€ì¼ ë³€í™”
            'shear': 0.0,        # ì „ë‹¨ ë¹„í™œì„±í™”
            'perspective': 0.0,  # ì›ê·¼ ë¹„í™œì„±í™”
            'flipud': 0.0,       # ìƒí•˜ë°˜ì „ ë¹„í™œì„±í™”
            'fliplr': 0.5,       # ì¢Œìš°ë°˜ì „ë§Œ ìœ ì§€
            'mosaic': 0.0,       # ëª¨ìì´í¬ OFF
            'mixup': 0.0,        # MixUp OFF
            'copy_paste': 0.0,   # Copy-Paste OFF
            'auto_augment': '',  # ìë™ì¦ê°• OFF
            'erasing': 0.0,      # Random Erasing OFF
        }

        print(f"ğŸ‹ï¸ í›ˆë ¨ ì‹œì‘...")
        print(f"   ğŸ“Š Epochs: {train_args['epochs']}")
        print(f"   ğŸ“¦ Batch: {train_args['batch']}")
        print(f"   ğŸ–¥ï¸ Device: {train_args['device']}")
        print(f"   ğŸ“ˆ Learning Rate: {lr0} ({'Pretrained' if self.pretrained_weights else 'Random Init'})")

        start_time = time.time()

        try:
            # í›ˆë ¨ ì‹¤í–‰
            results = model.train(**train_args)

            training_time = time.time() - start_time

            # ê²°ê³¼ ì €ì¥
            result_data = {
                'level': level_name,
                'model_name': model_config['name'],
                'model_path': str(model_config['path']),
                'pretrained_weights': self.pretrained_weights,
                'status': 'success',
                'training_time_seconds': training_time,
                'training_time_formatted': f"{training_time/3600:.1f}h {(training_time%3600)/60:.1f}m",
                'epochs_completed': train_args['epochs'],
                'batch_size': train_args['batch'],
                'device_used': train_args['device'],
                'learning_rate': lr0,
                'expected_improvement': model_config['expected_improvement'],
                'risk_level': model_config['risk'],
                'best_model_path': str(results.save_dir / 'weights' / 'best.pt') if hasattr(results, 'save_dir') else None,
                'last_model_path': str(results.save_dir / 'weights' / 'last.pt') if hasattr(results, 'save_dir') else None,
                'metrics': self.extract_metrics(results) if results else None
            }

            print(f"âœ… {level_name} í›ˆë ¨ ì™„ë£Œ!")
            print(f"â±ï¸ í›ˆë ¨ ì‹œê°„: {result_data['training_time_formatted']}")
            if result_data['best_model_path']:
                print(f"ğŸ’¾ ìµœê³  ëª¨ë¸: {result_data['best_model_path']}")

            return result_data

        except Exception as e:
            print(f"âŒ {level_name} í›ˆë ¨ ì‹¤íŒ¨: {e}")
            return {
                'level': level_name,
                'model_name': model_config['name'],
                'pretrained_weights': self.pretrained_weights,
                'status': 'failed',
                'error': str(e),
                'training_time_seconds': time.time() - start_time
            }

    def extract_metrics(self, results):
        """í›ˆë ¨ ê²°ê³¼ì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ"""
        try:
            if hasattr(results, 'results_dict'):
                return results.results_dict
            elif hasattr(results, 'metrics'):
                return results.metrics
            else:
                return {"note": "Metrics extraction not available"}
        except:
            return {"note": "Metrics extraction failed"}

    def train_all_levels(self, levels=None):
        """ëª¨ë“  ë ˆë²¨ ë˜ëŠ” ì§€ì •ëœ ë ˆë²¨ë“¤ í›ˆë ¨"""
        npu_models = self.get_npu_models()

        if levels is None:
            levels = list(npu_models.keys())

        print(f"ğŸš€ NPU ìµœì í™” ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        print(f"ğŸ“‚ ë°ì´í„°ì…‹: {self.data_yaml}")
        print(f"ğŸ¯ í›ˆë ¨ ë ˆë²¨: {', '.join(levels)}")
        print(f"ğŸ”„ ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜: {self.pretrained_weights if self.pretrained_weights else 'ì—†ìŒ'}")
        print(f"ğŸ“Š ê²°ê³¼ ì €ì¥: {self.results_dir}")
        print("=" * 80)

        for level in levels:
            if level not in npu_models:
                print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë ˆë²¨: {level}")
                continue

            model_config = npu_models[level]

            # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not model_config['path'].exists():
                print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_config['path']}")
                continue

            # í›ˆë ¨ ì‹¤í–‰
            result = self.train_model(model_config, level)
            if result:
                self.training_results[level] = result

        # ì „ì²´ ê²°ê³¼ ì €ì¥
        self.save_training_summary()

    def train_single_level(self, level):
        """ë‹¨ì¼ ë ˆë²¨ë§Œ í›ˆë ¨"""
        self.train_all_levels(levels=[level])

    def save_training_summary(self):
        """í›ˆë ¨ ê²°ê³¼ ìš”ì•½ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # JSON ê²°ê³¼ ì €ì¥
        json_path = self.results_dir / f"npu_training_summary_{timestamp}.json"
        with open(json_path, 'w') as f:
            json.dump(self.training_results, f, indent=2)

        # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
        md_path = self.results_dir / f"NPU_TRAINING_REPORT_{timestamp}.md"
        self.generate_markdown_report(md_path)

        print(f"\\nğŸ“Š í›ˆë ¨ ê²°ê³¼ ì €ì¥:")
        print(f"   ğŸ“„ JSON: {json_path}")
        print(f"   ğŸ“ Report: {md_path}")

    def generate_markdown_report(self, output_path):
        """ë§ˆí¬ë‹¤ìš´ í›ˆë ¨ ë¦¬í¬íŠ¸ ìƒì„±"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        report = f"""# NPU ìµœì í™” ëª¨ë¸ í›ˆë ¨ ê²°ê³¼ ë¦¬í¬íŠ¸ (ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì§€ì›)

**ìƒì„±ì¼**: {timestamp}
**ë°ì´í„°ì…‹**: Traffic Sign Detection (15 classes)
**ì´ í›ˆë ¨ ë ˆë²¨**: {len(self.training_results)}ê°œ
**ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜**: {self.pretrained_weights if self.pretrained_weights else 'ì—†ìŒ (ëœë¤ ì´ˆê¸°í™”)'}

## ğŸ“Š í›ˆë ¨ ê²°ê³¼ ìš”ì•½

| Level | ëª¨ë¸ëª… | ìƒíƒœ | í›ˆë ¨ì‹œê°„ | í•™ìŠµë¥  | ì˜ˆìƒê°œì„  | ìœ„í—˜ë„ | ëª¨ë¸ ê²½ë¡œ |
|-------|--------|------|----------|--------|----------|--------|-----------|
"""

        for level, result in self.training_results.items():
            status_emoji = "âœ…" if result['status'] == 'success' else "âŒ"
            training_time = result.get('training_time_formatted', 'N/A')
            learning_rate = result.get('learning_rate', 'N/A')
            expected_improvement = result.get('expected_improvement', 'N/A')
            risk = result.get('risk_level', 'N/A')
            model_path = Path(result.get('best_model_path', 'N/A')).name if result.get('best_model_path') else 'N/A'

            report += f"| {level.upper()} | {result['model_name']} | {status_emoji} {result['status']} | {training_time} | {learning_rate} | {expected_improvement} | {risk} | {model_path} |\\n"

        # ì„±ê³µí•œ í›ˆë ¨ë“¤ì˜ ìƒì„¸ ì •ë³´
        successful_trainings = {k: v for k, v in self.training_results.items() if v['status'] == 'success'}

        if successful_trainings:
            report += f"""

## ğŸ¯ ì„±ê³µí•œ í›ˆë ¨ ìƒì„¸ ì •ë³´

"""
            for level, result in successful_trainings.items():
                report += f"""### {level.upper()}: {result['model_name']}

- **ì„¤ëª…**: {result.get('description', 'N/A')}
- **ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜**: {result.get('pretrained_weights', 'ì—†ìŒ')}
- **í›ˆë ¨ ì‹œê°„**: {result['training_time_formatted']}
- **í•™ìŠµë¥ **: {result.get('learning_rate', 'N/A')}
- **ì™„ë£Œ ì—í­**: {result['epochs_completed']}
- **ë°°ì¹˜ í¬ê¸°**: {result['batch_size']}
- **ì‚¬ìš© ë””ë°”ì´ìŠ¤**: {result['device_used']}
- **ìµœê³  ëª¨ë¸**: `{result.get('best_model_path', 'N/A')}`
- **ìµœì¢… ëª¨ë¸**: `{result.get('last_model_path', 'N/A')}`

"""

        # ì‹¤íŒ¨í•œ í›ˆë ¨ë“¤
        failed_trainings = {k: v for k, v in self.training_results.items() if v['status'] == 'failed'}

        if failed_trainings:
            report += f"""

## âŒ ì‹¤íŒ¨í•œ í›ˆë ¨ ì •ë³´

"""
            for level, result in failed_trainings.items():
                report += f"""### {level.upper()}: {result['model_name']}

- **ì˜¤ë¥˜**: {result.get('error', 'Unknown error')}
- **ì†Œìš” ì‹œê°„**: {result['training_time_seconds']:.1f}ì´ˆ

"""

        report += f"""

## ğŸ”§ í›ˆë ¨ ì„¤ì •

### NPU ìµœì í™” í›ˆë ¨ íŒŒë¼ë¯¸í„°
- **ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜**: {self.pretrained_weights if self.pretrained_weights else 'ì—†ìŒ (ëœë¤ ì´ˆê¸°í™”)'}
- **Optimizer**: SGD (ì–‘ìí™” ì¹œí™”ì )
- **Learning Rate**: {'0.003 (ì‚¬ì „ í›ˆë ¨)' if self.pretrained_weights else '0.005 (ëœë¤ ì´ˆê¸°í™”)'}
- **Momentum**: 0.9
- **Weight Decay**: 0.001
- **Mixed Precision**: False (ì–‘ìí™” ì¤€ë¹„)

### NPU ì¹œí™”ì  ë°ì´í„° ì¦ê°•
- **ë³µì¡í•œ ì¦ê°• ë¹„í™œì„±í™”**: Mosaic, MixUp, AutoAugment ë“±
- **ë‹¨ìˆœ ì¦ê°•ë§Œ ì‚¬ìš©**: ì¢Œìš° ë°˜ì „, ìµœì†Œí•œì˜ ìƒ‰ìƒ ë³€í™”
- **íšŒì „/ì›ê·¼ ë³€í™˜ ë¹„í™œì„±í™”**: NPU íš¨ìœ¨ì„± ê³ ë ¤

## ğŸ“ˆ ë‹¤ìŒ ë‹¨ê³„

### ì„±ê³µí•œ ëª¨ë¸ë“¤
1. **ì •í™•ë„ í‰ê°€**: `scripts/01_evaluation/yolov11_pt_style_evaluator.py` ì‚¬ìš©
2. **NPU í˜¸í™˜ì„± ë¶„ì„**: `scripts/04_npu_specific/analyze_convertible_operators.py` ì‹¤í–‰
3. **Export í…ŒìŠ¤íŠ¸**: ONNX ë³€í™˜ ë° NPU íˆ´ì²´ì¸ ê²€ì¦

### ì‹¤íŒ¨í•œ ëª¨ë¸ë“¤
1. **ì˜¤ë¥˜ ë¶„ì„**: ëª¨ë¸ êµ¬ì¡° ë° ì˜ì¡´ì„± í™•ì¸
2. **ì»¤ìŠ¤í…€ ëª¨ë“ˆ êµ¬í˜„**: CSP, C2f ë“± í•„ìš” ëª¨ë“ˆ êµ¬í˜„
3. **ì¬í›ˆë ¨**: ë¬¸ì œ í•´ê²° í›„ ì¬ì‹œë„

---

**ğŸ’¡ ì°¸ê³ **: ì´ ë¦¬í¬íŠ¸ëŠ” ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„¸í•œ í›ˆë ¨ ë¡œê·¸ëŠ” ê° ëª¨ë¸ì˜ ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.
"""

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)

def main():
    parser = argparse.ArgumentParser(description='NPU ìµœì í™” YOLO ëª¨ë¸ í›ˆë ¨ (ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì§€ì›)')
    parser.add_argument('--level', type=str, choices=['level1', 'level2', 'level3', 'level4'],
                       help='íŠ¹ì • ë ˆë²¨ë§Œ í›ˆë ¨ (ê¸°ë³¸ê°’: ëª¨ë“  ë ˆë²¨)')
    parser.add_argument('--levels', type=str, nargs='+',
                       choices=['level1', 'level2', 'level3', 'level4'],
                       help='ì—¬ëŸ¬ ë ˆë²¨ ì„ íƒ (ì˜ˆ: --levels level1 level2)')
    parser.add_argument('--pretrained', type=str, default='yolov11n.pt',
                       help='ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ê²½ë¡œ (ê¸°ë³¸ê°’: yolov11n.pt)')
    parser.add_argument('--no-pretrained', action='store_true',
                       help='ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì™„ì „ ëœë¤ ì´ˆê¸°í™”)')

    args = parser.parse_args()

    # ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì„¤ì •
    pretrained_weights = None if args.no_pretrained else args.pretrained

    trainer = NPUOptimizedTrainer(pretrained_weights=pretrained_weights)

    # ì„¤ì • ì •ë³´ ì¶œë ¥
    if pretrained_weights:
        print(f"ğŸ“¦ ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜: {pretrained_weights}")
        print(f"   âš¡ ë¹ ë¥¸ ìˆ˜ë ´ ë° ë” ë‚˜ì€ ì´ˆê¸° ì„±ëŠ¥ ê¸°ëŒ€")
    else:
        print(f"âš ï¸ ëœë¤ ì´ˆê¸°í™” ëª¨ë“œ (í›ˆë ¨ ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)")

    if args.level:
        print(f"ğŸ¯ ë‹¨ì¼ ë ˆë²¨ í›ˆë ¨: {args.level}")
        trainer.train_single_level(args.level)
    elif args.levels:
        print(f"ğŸ¯ ì„ íƒëœ ë ˆë²¨ë“¤ í›ˆë ¨: {', '.join(args.levels)}")
        trainer.train_all_levels(levels=args.levels)
    else:
        print("ğŸ¯ ëª¨ë“  ë ˆë²¨ ìˆœì°¨ í›ˆë ¨")
        trainer.train_all_levels()

    print("\\nğŸ‰ í›ˆë ¨ ì™„ë£Œ!")

if __name__ == "__main__":
    main()